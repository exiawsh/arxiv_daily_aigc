[
    {
        "title": "The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text",
        "summary": "We present WorldCanvas, a framework for promptable world events that enables rich, user-directed simulation by combining text, trajectories, and reference images. Unlike text-only approaches and existing trajectory-controlled image-to-video methods, our multimodal approach combines trajectories -- encoding motion, timing, and visibility -- with natural language for semantic intent and reference images for visual grounding of object identity, enabling the generation of coherent, controllable events that include multi-agent interactions, object entry/exit, reference-guided appearance and counterintuitive events. The resulting videos demonstrate not only temporal coherence but also emergent consistency, preserving object identity and scene despite temporary disappearance. By supporting expressive world events generation, WorldCanvas advances world models from passive predictors to interactive, user-shaped simulators. Our project page is available at: https://worldcanvas.github.io/.",
        "url": "http://arxiv.org/abs/2512.16924v1",
        "published_date": "2025-12-18T18:59:59+00:00",
        "updated_date": "2025-12-18T18:59:59+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Hanlin Wang",
            "Hao Ouyang",
            "Qiuyu Wang",
            "Yue Yu",
            "Yihao Meng",
            "Wen Wang",
            "Ka Leong Cheng",
            "Shuailei Ma",
            "Qingyan Bai",
            "Yixuan Li",
            "Cheng Chen",
            "Yanhong Zeng",
            "Xing Zhu",
            "Yujun Shen",
            "Qifeng Chen"
        ],
        "tldr": "WorldCanvas introduces a multimodal framework for generating controllable world events by combining text prompts, trajectories, and reference images, enabling complex, coherent videos with multi-agent interactions and object permanence.",
        "tldr_zh": "WorldCanvas 提出了一个多模态框架，通过结合文本提示、轨迹和参考图像来生成可控的世界事件，从而能够生成具有多智能体交互和对象持久性的复杂连贯视频。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "FlashPortrait: 6x Faster Infinite Portrait Animation with Adaptive Latent Prediction",
        "summary": "Current diffusion-based acceleration methods for long-portrait animation struggle to ensure identity (ID) consistency. This paper presents FlashPortrait, an end-to-end video diffusion transformer capable of synthesizing ID-preserving, infinite-length videos while achieving up to 6x acceleration in inference speed. In particular, FlashPortrait begins by computing the identity-agnostic facial expression features with an off-the-shelf extractor. It then introduces a Normalized Facial Expression Block to align facial features with diffusion latents by normalizing them with their respective means and variances, thereby improving identity stability in facial modeling. During inference, FlashPortrait adopts a dynamic sliding-window scheme with weighted blending in overlapping areas, ensuring smooth transitions and ID consistency in long animations. In each context window, based on the latent variation rate at particular timesteps and the derivative magnitude ratio among diffusion layers, FlashPortrait utilizes higher-order latent derivatives at the current timestep to directly predict latents at future timesteps, thereby skipping several denoising steps and achieving 6x speed acceleration. Experiments on benchmarks show the effectiveness of FlashPortrait both qualitatively and quantitatively.",
        "url": "http://arxiv.org/abs/2512.16900v1",
        "published_date": "2025-12-18T18:56:05+00:00",
        "updated_date": "2025-12-18T18:56:05+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Shuyuan Tu",
            "Yueming Pan",
            "Yinming Huang",
            "Xintong Han",
            "Zhen Xing",
            "Qi Dai",
            "Kai Qiu",
            "Chong Luo",
            "Zuxuan Wu"
        ],
        "tldr": "FlashPortrait introduces a video diffusion transformer for generating identity-preserving, infinite-length portrait animations with 6x acceleration by using adaptive latent prediction and a normalized facial expression block.",
        "tldr_zh": "FlashPortrait 提出了一种视频扩散 Transformer，通过自适应潜在预测和归一化面部表情块，以 6 倍的加速生成保持身份一致性的无限长度人像动画。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]