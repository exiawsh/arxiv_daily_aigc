[
    {
        "title": "Counterfactual World Models via Digital Twin-conditioned Video Diffusion",
        "summary": "World models learn to predict the temporal evolution of visual observations given a control signal, potentially enabling agents to reason about environments through forward simulation. Because of the focus on forward simulation, current world models generate predictions based on factual observations. For many emerging applications, such as comprehensive evaluations of physical AI behavior under varying conditions, the ability of world models to answer counterfactual queries, such as \"what would happen if this object was removed?\", is of increasing importance. We formalize counterfactual world models that additionally take interventions as explicit inputs, predicting temporal sequences under hypothetical modifications to observed scene properties. Traditional world models operate directly on entangled pixel-space representations where object properties and relationships cannot be selectively modified. This modeling choice prevents targeted interventions on specific scene properties. We introduce CWMDT, a framework to overcome those limitations, turning standard video diffusion models into effective counterfactual world models. First, CWMDT constructs digital twins of observed scenes to explicitly encode objects and their relationships, represented as structured text. Second, CWMDT applies large language models to reason over these representations and predict how a counterfactual intervention propagates through time to alter the observed scene. Third, CWMDT conditions a video diffusion model with the modified representation to generate counterfactual visual sequences. Evaluations on two benchmarks show that the CWMDT approach achieves state-of-the-art performance, suggesting that alternative representations of videos, such as the digital twins considered here, offer powerful control signals for video forward simulation-based world models.",
        "url": "http://arxiv.org/abs/2511.17481v1",
        "published_date": "2025-11-21T18:37:23+00:00",
        "updated_date": "2025-11-21T18:37:23+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Yiqing Shen",
            "Aiza Maksutova",
            "Chenjia Li",
            "Mathias Unberath"
        ],
        "tldr": "The paper introduces CWMDT, a framework that uses digital twins and video diffusion models to create counterfactual world models, enabling the prediction of video sequences under hypothetical interventions.",
        "tldr_zh": "该论文介绍了CWMDT，一个利用数字孪生和视频扩散模型创建反事实世界模型的框架，能够预测在假设干预下的视频序列。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]