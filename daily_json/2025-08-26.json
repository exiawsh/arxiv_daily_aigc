[
    {
        "title": "HERO: Hierarchical Extrapolation and Refresh for Efficient World Models",
        "summary": "Generation-driven world models create immersive virtual environments but\nsuffer slow inference due to the iterative nature of diffusion models. While\nrecent advances have improved diffusion model efficiency, directly applying\nthese techniques to world models introduces limitations such as quality\ndegradation. In this paper, we present HERO, a training-free hierarchical\nacceleration framework tailored for efficient world models. Owing to the\nmulti-modal nature of world models, we identify a feature coupling phenomenon,\nwherein shallow layers exhibit high temporal variability, while deeper layers\nyield more stable feature representations. Motivated by this, HERO adopts\nhierarchical strategies to accelerate inference: (i) In shallow layers, a\npatch-wise refresh mechanism efficiently selects tokens for recomputation. With\npatch-wise sampling and frequency-aware tracking, it avoids extra metric\ncomputation and remain compatible with FlashAttention. (ii) In deeper layers, a\nlinear extrapolation scheme directly estimates intermediate features. This\ncompletely bypasses the computations in attention modules and feed-forward\nnetworks. Our experiments show that HERO achieves a 1.73$\\times$ speedup with\nminimal quality degradation, significantly outperforming existing diffusion\nacceleration methods.",
        "url": "http://arxiv.org/abs/2508.17588v1",
        "published_date": "2025-08-25T01:22:15+00:00",
        "updated_date": "2025-08-25T01:22:15+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Quanjian Song",
            "Xinyu Wang",
            "Donghao Zhou",
            "Jingyu Lin",
            "Cunjian Chen",
            "Yue Ma",
            "Xiu Li"
        ],
        "tldr": "The paper introduces HERO, a training-free hierarchical acceleration framework for world models that improves inference speed by using patch-wise refresh in shallow layers and linear extrapolation in deeper layers, achieving a 1.73x speedup with minimal quality degradation.",
        "tldr_zh": "该论文提出了HERO，一种用于世界模型的免训练分层加速框架，通过在浅层中使用分块刷新，在深层中使用线性外推来提高推理速度，实现了1.73倍的加速，且质量损失极小。",
        "relevance_score": 8,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Language-Guided Temporal Token Pruning for Efficient VideoLLM Processing",
        "summary": "Vision Language Models (VLMs) struggle with long-form videos due to the\nquadratic complexity of attention mechanisms. We propose Language-Guided\nTemporal Token Pruning (LGTTP), which leverages temporal cues from queries to\nadaptively prune video tokens, preserving contextual continuity while reducing\ncomputational overhead. Unlike uniform pruning or keyframe selection, LGTTP\nretains higher token density in temporally relevant segments. Our\nmodel-agnostic framework integrates with TimeChat and LLaVA-Video, achieving a\n65% reduction in computation while preserving 97-99% of the original\nperformance. On QVHighlights, LGTTP improves HIT@1 by +9.5%, and on\nCharades-STA, it retains 99.6% of R@1. It excels on queries with explicit\ntemporal markers and remains effective across general video understanding\ntasks.",
        "url": "http://arxiv.org/abs/2508.17686v1",
        "published_date": "2025-08-25T05:51:21+00:00",
        "updated_date": "2025-08-25T05:51:21+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Yogesh Kumar"
        ],
        "tldr": "The paper introduces Language-Guided Temporal Token Pruning (LGTTP) to efficiently process long videos in VideoLLMs by adaptively pruning video tokens based on temporal cues from language queries, achieving significant computational reduction with minimal performance loss.",
        "tldr_zh": "该论文介绍了语言引导的时间令牌剪枝（LGTTP），通过基于语言查询的时间线索自适应地剪枝视频令牌，从而高效地处理VideoLLM中的长视频，在计算量大幅减少的同时，性能损失极小。",
        "relevance_score": 3,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 5
    }
]