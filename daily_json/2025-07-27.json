[
    {
        "title": "ChoreoMuse: Robust Music-to-Dance Video Generation with Style Transfer and Beat-Adherent Motion",
        "summary": "Modern artistic productions increasingly demand automated choreography\ngeneration that adapts to diverse musical styles and individual dancer\ncharacteristics. Existing approaches often fail to produce high-quality dance\nvideos that harmonize with both musical rhythm and user-defined choreography\nstyles, limiting their applicability in real-world creative contexts. To\naddress this gap, we introduce ChoreoMuse, a diffusion-based framework that\nuses SMPL format parameters and their variation version as intermediaries\nbetween music and video generation, thereby overcoming the usual constraints\nimposed by video resolution. Critically, ChoreoMuse supports\nstyle-controllable, high-fidelity dance video generation across diverse musical\ngenres and individual dancer characteristics, including the flexibility to\nhandle any reference individual at any resolution. Our method employs a novel\nmusic encoder MotionTune to capture motion cues from audio, ensuring that the\ngenerated choreography closely follows the beat and expressive qualities of the\ninput music. To quantitatively evaluate how well the generated dances match\nboth musical and choreographic styles, we introduce two new metrics that\nmeasure alignment with the intended stylistic cues. Extensive experiments\nconfirm that ChoreoMuse achieves state-of-the-art performance across multiple\ndimensions, including video quality, beat alignment, dance diversity, and style\nadherence, demonstrating its potential as a robust solution for a wide range of\ncreative applications. Video results can be found on our project page:\nhttps://choreomuse.github.io.",
        "url": "http://arxiv.org/abs/2507.19836v1",
        "published_date": "2025-07-26T07:17:50+00:00",
        "updated_date": "2025-07-26T07:17:50+00:00",
        "categories": [
            "cs.GR",
            "cs.AI",
            "cs.CV",
            "cs.MM",
            "cs.SD"
        ],
        "authors": [
            "Xuanchen Wang",
            "Heng Wang",
            "Weidong Cai"
        ],
        "tldr": "ChoreoMuse is a diffusion-based framework for generating high-fidelity, style-controllable dance videos from music using SMPL parameters, achieving state-of-the-art performance in video quality, beat alignment, and style adherence.",
        "tldr_zh": "ChoreoMuse是一个基于扩散模型的框架，利用SMPL参数从音乐生成高质量、风格可控的舞蹈视频，并在视频质量、节拍对齐和风格一致性方面实现了最先进的性能。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 7
    }
]