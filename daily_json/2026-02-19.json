[
    {
        "title": "CHAI: CacHe Attention Inference for text2video",
        "summary": "Text-to-video diffusion models deliver impressive results but remain slow because of the sequential denoising of 3D latents. Existing approaches to speed up inference either require expensive model retraining or use heuristic-based step skipping, which struggles to maintain video quality as the number of denoising steps decreases. Our work, CHAI, aims to use cross-inference caching to reduce latency while maintaining video quality. We introduce Cache Attention as an effective method for attending to shared objects/scenes across cross-inference latents. This selective attention mechanism enables effective reuse of cached latents across semantically related prompts, yielding high cache hit rates. We show that it is possible to generate high-quality videos using Cache Attention with as few as 8 denoising steps. When integrated into the overall system, CHAI is 1.65x - 3.35x faster than baseline OpenSora 1.2 while maintaining video quality.",
        "url": "http://arxiv.org/abs/2602.16132v1",
        "published_date": "2026-02-18T01:53:29+00:00",
        "updated_date": "2026-02-18T01:53:29+00:00",
        "categories": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Joel Mathew Cherian",
            "Ashutosh Muralidhara Bharadwaj",
            "Vima Gupta",
            "Anand Padmanabha Iyer"
        ],
        "tldr": "CHAI introduces a cache attention mechanism for text-to-video generation that reuses latents across semantically related prompts, significantly accelerating inference speed while maintaining video quality by reducing the number of denoising steps needed.",
        "tldr_zh": "CHAI 引入了一种用于文本到视频生成的缓存注意力机制，通过重用语义相关的提示之间的潜在变量，显著加快推理速度，同时通过减少所需的去噪步骤来保持视频质量。",
        "relevance_score": 8,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 9,
        "overall_priority_score": 8
    }
]